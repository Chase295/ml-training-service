version: '3.8'
services:
  ml-ui:
    build:
      context: ./ml-ui
      dockerfile: Dockerfile
    container_name: ml-ui
    restart: unless-stopped
    ports:
      - "3002:80"  # UI + API über Reverse Proxy auf Port 3002
    depends_on:
      - ml-service
    # Keine Environment-Variablen nötig - hardcoded wie pump-find
    networks:
      - ml-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # Vereinter ML-Service (NUR INTERN verfügbar wie pump-service in pump-find)
  ml-service:
    build: .
    container_name: ml-service
    restart: unless-stopped
    # KEINE externen ports - nur über Reverse Proxy zugänglich (wie pump-find)
    expose:
      - "8000"  # Intern für ml-ui verfügbar
    environment:
      # Datenbank (bleibt gleich)
      - DB_DSN=${DB_DSN:-postgresql://postgres:9HVxi6hN6j7xpmqUx84o@100.118.155.75:5432/beta}
      
      # API-Konfiguration
      - API_PORT=8000
      - MODEL_STORAGE_PATH=/app/models
      
      # Job-Management (bleibt gleich)
      - JOB_POLL_INTERVAL=5
      - MAX_CONCURRENT_JOBS=2
    volumes:
      - ./models:/app/models
      - ./config:/app/config:rw
    networks:
      - ml-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

networks:
  ml-network:
    driver: bridge

volumes:
  ml-models:
    driver: local
  ml-config:
    driver: local
