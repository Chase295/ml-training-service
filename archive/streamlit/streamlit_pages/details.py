"""
Details Page Module
Modell-Details Seite
"""
import streamlit as st
import pandas as pd
import plotly.express as px
from datetime import datetime, timezone, timedelta
from typing import List, Dict, Any, Optional

# Import aus streamlit_utils
from streamlit_utils import (
    api_get, api_post, api_delete, api_patch,
    AVAILABLE_FEATURES, FEATURE_CATEGORIES, CRITICAL_FEATURES,
    API_BASE_URL
)

def page_details():
    """Modell-Details - Ãœberarbeitete Version mit besserer Ãœbersichtlichkeit"""
    # ZurÃ¼ck-Button
    col1, col2 = st.columns([1, 3])
    with col1:
        if st.button("â† ZurÃ¼ck zur Ãœbersicht", key="back_to_overview_top", use_container_width=True):
            st.session_state.pop('page', None)
            st.session_state.pop('details_model_id', None)

    st.divider()

    model_id = st.session_state.get('details_model_id')
    if not model_id:
        st.warning("âš ï¸ Kein Modell ausgewÃ¤hlt")
        return
    
    model = api_get(f"/api/models/{model_id}")
    if not model:
        st.error("âŒ Modell nicht gefunden")
        return
    
    # Header mit wichtigsten Infos
    model_name = model.get('name', 'Unbenannt')
    model_type = model.get('model_type', 'N/A')
    type_emoji = "ðŸŒ²" if model_type == "random_forest" else "ðŸš€" if model_type == "xgboost" else "ðŸ¤–"
    status = model.get('status', 'N/A')
    
    # Header mit Status-Badge
    header_col1, header_col2 = st.columns([3, 1])
    with header_col1:
        st.title(f"{type_emoji} {model_name}")
    with header_col2:
        if status == "READY":
            st.success("âœ… READY")
        elif status == "TRAINING":
            st.info("ðŸ”„ TRAINING")
        else:
            st.error(f"âŒ {status}")
    
    # Quick Info Cards
    st.subheader("ðŸ“Š Quick Overview")
    
    # ErklÃ¤rung zu den Quick Overview Metriken
    with st.expander("â„¹ï¸ Was bedeuten diese Metriken?", expanded=False):
        st.markdown("""
        **Accuracy (Genauigkeit):**
        - Zeigt an, wie viele Vorhersagen insgesamt korrekt waren
        - Formel: (TP + TN) / (TP + TN + FP + FN)
        - **Beispiel:** 85% Accuracy bedeutet: Von 100 Vorhersagen waren 85 korrekt
        - âš ï¸ **Achtung:** Bei unausgewogenen Daten kann Accuracy irrefÃ¼hrend sein!
        
        **F1-Score:**
        - Harmonisches Mittel aus Precision und Recall
        - Formel: 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
        - **Bedeutung:** Gibt einen ausgewogenen Wert fÃ¼r beide Metriken
        - **Ideal:** Nahe bei 1.0 (100%)
        - **Praktisch:** >0.7 ist gut, >0.8 ist sehr gut
        
        **Precision (PrÃ¤zision):**
        - Von allen "Positiv"-Vorhersagen, wie viele waren wirklich positiv?
        - Formel: TP / (TP + FP)
        - **Beispiel:** 90% Precision = Von 100 "Pump"-Vorhersagen waren 90 wirklich Pumps
        - **Wichtig fÃ¼r:** Minimierung von FehlkÃ¤ufen (False Positives)
        
        **Recall (SensitivitÃ¤t):**
        - Von allen echten Pumps, wie viele hat das Modell gefunden?
        - Formel: TP / (TP + FN)
        - **Beispiel:** 80% Recall = Von 100 echten Pumps wurden 80 erkannt
        - **Wichtig fÃ¼r:** Keine echten Pumps verpassen (False Negatives)
        
        **ROC-AUC (Receiver Operating Characteristic - Area Under Curve):**
        - Misst die FÃ¤higkeit, zwischen Positiv und Negativ zu unterscheiden
        - **Werte:** 0.5 = zufÃ¤llig, 0.7-0.8 = akzeptabel, 0.8-0.9 = gut, >0.9 = sehr gut
        - **Bedeutung:** Je hÃ¶her, desto besser kann das Modell unterscheiden
        """)
    
    quick_col1, quick_col2, quick_col3, quick_col4, quick_col5 = st.columns(5)
    
    with quick_col1:
        accuracy = model.get('training_accuracy')
        if accuracy:
            st.metric("Accuracy", f"{accuracy:.2%}", help="Anteil korrekter Vorhersagen")
        else:
            st.metric("Accuracy", "N/A")
    
    with quick_col2:
        f1 = model.get('training_f1')
        if f1:
            st.metric("F1-Score", f"{f1:.2%}", help="Harmonisches Mittel aus Precision und Recall")
        else:
            st.metric("F1-Score", "N/A")
    
    with quick_col3:
        precision = model.get('training_precision')
        if precision:
            st.metric("Precision", f"{precision:.2%}", help="Anteil korrekter Positiv-Vorhersagen")
        else:
            st.metric("Precision", "N/A")
    
    with quick_col4:
        recall = model.get('training_recall')
        if recall:
            st.metric("Recall", f"{recall:.2%}", help="Anteil gefundener Positiver")
        else:
            st.metric("Recall", "N/A")
    
    with quick_col5:
        roc_auc = model.get('roc_auc')
        if roc_auc:
            quality = "ðŸŸ¢" if roc_auc > 0.9 else "ðŸŸ¡" if roc_auc > 0.7 else "ðŸ”´"
            st.metric("ROC-AUC", f"{quality} {roc_auc:.3f}", help="Area Under ROC Curve")
        else:
            st.metric("ROC-AUC", "N/A")
    
    st.divider()
    
    # Tabs fÃ¼r bessere Organisation
    tab_overview, tab_performance, tab_config, tab_features, tab_details = st.tabs([
        "ðŸ“Š Ãœbersicht",
        "ðŸ“ˆ Performance",
        "âš™ï¸ Konfiguration",
        "ðŸŽ¯ Features",
        "ðŸ“‹ Details"
    ])
    
    # TAB 1: Ãœbersicht
    with tab_overview:
        # Basis-Informationen
        st.subheader("â„¹ï¸ Basis-Informationen")
        info_col1, info_col2, info_col3, info_col4 = st.columns(4)
        
        with info_col1:
            st.markdown("**Modell-Typ**")
            st.write(f"{type_emoji} {model_type}")
        
        with info_col2:
            st.markdown("**Modell-ID**")
            st.code(f"#{model_id}", language=None)
        
        with info_col3:
            st.markdown("**Erstellt am**")
            created = model.get('created_at', '')
            if created:
                try:
                    if isinstance(created, str):
                        created_dt = datetime.fromisoformat(created.replace('Z', '+00:00'))
                    else:
                        created_dt = created
                    st.write(created_dt.strftime("%d.%m.%Y %H:%M"))
                except:
                    st.write(str(created)[:19] if len(str(created)) > 19 else str(created))
            else:
                st.write("N/A")
        
        with info_col4:
            st.markdown("**Status**")
            if status == "READY":
                st.success("âœ… READY")
            elif status == "TRAINING":
                st.info("ðŸ”„ TRAINING")
            else:
                st.error(f"âŒ {status}")
    
    # Beschreibung
    description = model.get('description')
    if description:
        st.subheader("ðŸ“ Beschreibung")
        st.info(description)
    
        # Confusion Matrix (kompakt)
        confusion_matrix = model.get('confusion_matrix')
        if confusion_matrix:
            st.subheader("ðŸ”¢ Confusion Matrix")
            
        # AusfÃ¼hrliche ErklÃ¤rung
            with st.expander("â„¹ï¸ Was ist eine Confusion Matrix?", expanded=False):
                st.markdown("""
                Die **Confusion Matrix** zeigt, wie gut das Modell Vorhersagen macht:
                
                **âœ… True Positive (TP):**
                - Das Modell sagt "Pump" vorher und es ist wirklich ein Pump
                - **Gut!** â†’ Du kaufst und es steigt tatsÃ¤chlich
                - **Bedeutung:** Erfolgreiche Vorhersagen
                
                **âœ… True Negative (TN):**
                - Das Modell sagt "Kein Pump" vorher und es ist wirklich kein Pump
                - **Gut!** â†’ Du kaufst nicht und verpasst nichts
                - **Bedeutung:** Korrekte Ablehnungen
                
                **âŒ False Positive (FP):**
                - Das Modell sagt "Pump" vorher, aber es ist KEIN Pump
                - **Schlecht!** â†’ Du kaufst, aber der Preis steigt nicht
                - **Bedeutung:** FehlkÃ¤ufe, Geldverlust
                - **Ziel:** So niedrig wie mÃ¶glich halten
                
                **âŒ False Negative (FN):**
                - Das Modell sagt "Kein Pump" vorher, aber es IST ein Pump
                - **Schlecht!** â†’ Du verpasst eine echte Chance
                - **Bedeutung:** Verpasste Gewinne
                - **Ziel:** So niedrig wie mÃ¶glich halten
                
                **ðŸ’¡ Praktische Interpretation:**
                - **Hohe TP + niedrige FP** = Viele richtige Pump-Erkennungen, wenige FehlkÃ¤ufe
                - **Hohe TN + niedrige FN** = Viele richtige Ablehnungen, wenige verpasste Chancen
                - **Ideal:** Hohe TP und TN, niedrige FP und FN
                """)
            
            cm_col1, cm_col2, cm_col3, cm_col4 = st.columns(4)
            
            with cm_col1:
                tp = confusion_matrix.get('tp', 0)
                st.metric("âœ… TP", tp, help="True Positive: Korrekt als Positiv erkannt")
                st.caption("Erfolgreiche Pump-Erkennungen")
            
            with cm_col2:
                tn = confusion_matrix.get('tn', 0)
                st.metric("âœ… TN", tn, help="True Negative: Korrekt als Negativ erkannt")
                st.caption("Korrekte Ablehnungen")
            
            with cm_col3:
                fp = confusion_matrix.get('fp', 0)
                st.metric("âŒ FP", fp, delta=f"-{fp}", delta_color="inverse", help="False Positive: Falsch als Positiv erkannt")
                st.caption("FehlkÃ¤ufe (Geldverlust)")
            
            with cm_col4:
                fn = confusion_matrix.get('fn', 0)
                st.metric("âŒ FN", fn, delta=f"-{fn}", delta_color="inverse", help="False Negative: Falsch als Negativ erkannt")
                st.caption("Verpasste Chancen")
            
            # Visualisierung als Tabelle
            st.markdown("**ðŸ“Š Matrix-Darstellung:**")
            cm_data = {
                'TatsÃ¤chlich': ['Negativ', 'Positiv'],
                'Vorhergesagt: Negativ': [tn, fn],
                'Vorhergesagt: Positiv': [fp, tp]
            }
            cm_df = pd.DataFrame(cm_data)
            st.dataframe(cm_df, use_container_width=True, hide_index=True)
            
            # Interpretation
            total = tp + tn + fp + fn
            if total > 0:
                accuracy_calc = (tp + tn) / total
                precision_calc = tp / (tp + fp) if (tp + fp) > 0 else 0
                recall_calc = tp / (tp + fn) if (tp + fn) > 0 else 0
                
                st.info(f"""
                **ðŸ“ˆ Interpretation:**
                - **Gesamt Vorhersagen:** {total}
                - **Korrekt:** {tp + tn} ({accuracy_calc:.1%})
                - **Fehler:** {fp + fn} ({(fp + fn)/total:.1%})
                - **Precision (aus Matrix):** {precision_calc:.1%} - Von {tp + fp} "Pump"-Vorhersagen waren {tp} richtig
                - **Recall (aus Matrix):** {recall_calc:.1%} - Von {tp + fn} echten Pumps wurden {tp} erkannt
                """)
        
        # Profit-Simulation
        simulated_profit = model.get('simulated_profit_pct')
        if simulated_profit is not None:
            st.subheader("ðŸ’° Profit-Simulation")
            
            # ErklÃ¤rung zur Profit-Simulation
            with st.expander("â„¹ï¸ Wie funktioniert die Profit-Simulation?", expanded=False):
                st.markdown("""
                Die **Profit-Simulation** berechnet einen theoretischen Gewinn/Verlust basierend auf den Vorhersagen:
                
                **ðŸ“Š Berechnungsformel:**
                - **+1% Profit** fÃ¼r jeden True Positive (TP)
                  - Du kaufst basierend auf der Vorhersage â†’ Preis steigt tatsÃ¤chlich â†’ +1% Gewinn
                
                - **-0.5% Verlust** fÃ¼r jeden False Positive (FP)
                  - Du kaufst basierend auf der Vorhersage â†’ Preis steigt NICHT â†’ -0.5% Verlust
                
                - **0%** fÃ¼r True Negative (TN) und False Negative (FN)
                  - TN: Du kaufst nicht â†’ kein Gewinn, aber auch kein Verlust
                  - FN: Du verpasst eine Chance â†’ kein Gewinn, aber auch kein Verlust
                
                **ðŸ’¡ Beispiel:**
                - 100 TP â†’ +100% Gewinn
                - 20 FP â†’ -10% Verlust
                - **Gesamt:** +90% Profit
                
                **âš ï¸ Wichtig:**
                - Dies ist eine **vereinfachte Simulation**
                - Echte Gewinne hÃ¤ngen von vielen Faktoren ab (Timing, VolatilitÃ¤t, etc.)
                - Die Simulation zeigt die **relative Performance** verschiedener Modelle
                """)
            
            profit_col1, profit_col2 = st.columns([1, 2])
            with profit_col1:
                profit_quality = "ðŸŸ¢ Sehr profitabel" if simulated_profit > 5 else "ðŸŸ¡ Profitabel" if simulated_profit > 0 else "ðŸ”´ Verlust"
                st.metric("ðŸ’° Simulierter Profit", f"{simulated_profit:.2f}%", help="Simulierter Profit basierend auf TP/FP")
                st.caption(profit_quality)
            
            with profit_col2:
                tp = confusion_matrix.get('tp', 0) if confusion_matrix else 0
                fp = confusion_matrix.get('fp', 0) if confusion_matrix else 0
                profit_from_tp = tp * 1.0
                loss_from_fp = fp * 0.5
                st.info(f"""
                **ðŸ“Š Detaillierte Berechnung:**
                - {tp} TP Ã— 1% = +{profit_from_tp:.2f}%
                - {fp} FP Ã— 0.5% = -{loss_from_fp:.2f}%
                - **Gesamt:** {simulated_profit:.2f}%
                """)
    
    # TAB 2: Performance
    with tab_performance:
        st.subheader("ðŸ“Š Standard-Metriken")
        
        # ErklÃ¤rung zu Standard-Metriken
        with st.expander("â„¹ï¸ Detaillierte ErklÃ¤rung der Standard-Metriken", expanded=False):
            st.markdown("""
            ### Accuracy (Genauigkeit)
            **Was es misst:** Anteil aller korrekten Vorhersagen (sowohl positive als auch negative)
            
            **Formel:** (TP + TN) / (TP + TN + FP + FN)
            
            **Beispiel:**
            - 100 Vorhersagen insgesamt
            - 85 waren korrekt (TP + TN)
            - **Accuracy = 85%**
            
            **âš ï¸ Wichtig:** Bei unausgewogenen Daten (z.B. 90% negative, 10% positive) kann Accuracy irrefÃ¼hrend sein!
            Ein Modell, das immer "negativ" sagt, hÃ¤tte 90% Accuracy, ist aber nutzlos.
            
            ---
            
            ### Precision (PrÃ¤zision)
            **Was es misst:** Von allen "Pump"-Vorhersagen, wie viele waren wirklich Pumps?
            
            **Formel:** TP / (TP + FP)
            
            **Beispiel:**
            - Modell sagt 100x "Pump" vorher
            - 90 davon waren wirklich Pumps (TP)
            - 10 waren keine Pumps (FP)
            - **Precision = 90%**
            
            **Praktische Bedeutung:** 
            - Hohe Precision = Wenige FehlkÃ¤ufe
            - **Wichtig fÃ¼r:** Minimierung von Geldverlusten durch falsche KÃ¤ufe
            
            ---
            
            ### Recall (SensitivitÃ¤t / Trefferquote)
            **Was es misst:** Von allen echten Pumps, wie viele hat das Modell gefunden?
            
            **Formel:** TP / (TP + FN)
            
            **Beispiel:**
            - Es gab 100 echte Pumps
            - Modell hat 80 davon erkannt (TP)
            - 20 wurden verpasst (FN)
            - **Recall = 80%**
            
            **Praktische Bedeutung:**
            - Hoher Recall = Wenige verpasste Chancen
            - **Wichtig fÃ¼r:** Maximierung von GewinnmÃ¶glichkeiten
            
            ---
            
            ### F1-Score
            **Was es misst:** Ausgewogenes MaÃŸ zwischen Precision und Recall
            
            **Formel:** 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
            
            **Beispiel:**
            - Precision = 90%, Recall = 80%
            - **F1-Score = 2 Ã— (0.9 Ã— 0.8) / (0.9 + 0.8) = 0.847 (84.7%)**
            
            **Praktische Bedeutung:**
            - Gibt einen einzigen Wert, der beide Metriken berÃ¼cksichtigt
            - **Ideal:** Nahe bei 1.0 (100%)
            - **Gut:** >0.7, **Sehr gut:** >0.8
            
            **ðŸ’¡ Trade-off:**
            - Hohe Precision â†’ Niedrige Recall (wenige FehlkÃ¤ufe, aber viele verpasste Chancen)
            - Hohe Recall â†’ Niedrige Precision (viele erkannte Pumps, aber auch viele FehlkÃ¤ufe)
            - F1-Score hilft, den optimalen Balance-Punkt zu finden
            """)
            
            perf_col1, perf_col2, perf_col3, perf_col4 = st.columns(4)
            with perf_col1:
                accuracy = model.get('training_accuracy')
                if accuracy:
                    quality = "ðŸŸ¢ Sehr gut" if accuracy > 0.9 else "ðŸŸ¡ Gut" if accuracy > 0.7 else "ðŸ”´ Verbesserung nÃ¶tig"
                    st.metric("Accuracy", f"{accuracy:.4f}", help="Anteil korrekter Vorhersagen (0-1, hÃ¶her = besser)")
                    st.caption(quality)
                else:
                    st.write("Accuracy: N/A")
            
            with perf_col2:
                f1 = model.get('training_f1')
                if f1:
                    quality = "ðŸŸ¢ Sehr gut" if f1 > 0.8 else "ðŸŸ¡ Gut" if f1 > 0.7 else "ðŸ”´ Verbesserung nÃ¶tig"
                    st.metric("F1-Score", f"{f1:.4f}", help="Harmonisches Mittel aus Precision und Recall (0-1, hÃ¶her = besser)")
                    st.caption(quality)
                else:
                    st.write("F1-Score: N/A")
            
            with perf_col3:
                precision = model.get('training_precision')
                if precision:
                    quality = "ðŸŸ¢ Sehr gut" if precision > 0.8 else "ðŸŸ¡ Gut" if precision > 0.7 else "ðŸ”´ Verbesserung nÃ¶tig"
                    st.metric("Precision", f"{precision:.4f}", help="Von allen 'Positiv'-Vorhersagen, wie viele waren wirklich positiv?")
                    st.caption(quality)
                else:
                    st.write("Precision: N/A")
            
            with perf_col4:
                recall = model.get('training_recall')
                if recall:
                    quality = "ðŸŸ¢ Sehr gut" if recall > 0.8 else "ðŸŸ¡ Gut" if recall > 0.7 else "ðŸ”´ Verbesserung nÃ¶tig"
                    st.metric("Recall", f"{recall:.4f}", help="Von allen echten Positiven, wie viele hat das Modell gefunden?")
                    st.caption(quality)
                else:
                    st.write("Recall: N/A")
    
    st.divider()
    
    st.subheader("ðŸ“ˆ Erweiterte Metriken")
    
    # ErklÃ¤rung zu erweiterten Metriken
    with st.expander("â„¹ï¸ Detaillierte ErklÃ¤rung der erweiterten Metriken", expanded=False):
        st.markdown("""
            ### ROC-AUC (Receiver Operating Characteristic - Area Under Curve)
            **Was es misst:** Die FÃ¤higkeit des Modells, zwischen positiven und negativen FÃ¤llen zu unterscheiden
            
            **Werte-Bereich:** 0.0 bis 1.0
            
            **Interpretation:**
            - **0.5** = ZufÃ¤llig (wie MÃ¼nzwurf) - Modell ist nutzlos
            - **0.7-0.8** = Akzeptabel - Modell kann unterscheiden
            - **0.8-0.9** = Gut - Gute UnterscheidungsfÃ¤higkeit
            - **>0.9** = Sehr gut - Exzellente UnterscheidungsfÃ¤higkeit
            - **1.0** = Perfekt (in der Praxis nicht erreichbar)
            
            **Praktische Bedeutung:**
            - HÃ¶herer ROC-AUC = Modell kann besser zwischen Pump und Nicht-Pump unterscheiden
            - **Wichtig fÃ¼r:** Vergleich verschiedener Modelle
            
            ---
            
            ### MCC (Matthews Correlation Coefficient)
            **Was es misst:** Ausgewogene Metrik, die alle vier Werte der Confusion Matrix berÃ¼cksichtigt
            
            **Formel:** (TP Ã— TN - FP Ã— FN) / âˆš((TP + FP) Ã— (TP + FN) Ã— (TN + FP) Ã— (TN + FN))
            
            **Werte-Bereich:** -1.0 bis +1.0
            
            **Interpretation:**
            - **+1.0** = Perfekte Vorhersage
            - **0.0** = ZufÃ¤llig
            - **-1.0** = Perfekte umgekehrte Vorhersage (Modell ist komplett falsch)
            
            **Vorteil:** Funktioniert auch bei unausgewogenen Daten besser als Accuracy
            
            ---
            
            ### False Positive Rate (FPR)
            **Was es misst:** Anteil der negativen FÃ¤lle, die fÃ¤lschlicherweise als positiv klassifiziert wurden
            
            **Formel:** FP / (FP + TN)
            
            **Beispiel:**
            - 100 echte "Nicht-Pumps"
            - 10 wurden fÃ¤lschlicherweise als "Pump" erkannt (FP)
            - **FPR = 10%**
            
            **Praktische Bedeutung:**
            - Niedrige FPR = Wenige FehlkÃ¤ufe
            - **Ziel:** <10% ist gut, <5% ist sehr gut
            
            ---
            
            ### False Negative Rate (FNR)
            **Was es misst:** Anteil der positiven FÃ¤lle, die fÃ¤lschlicherweise als negativ klassifiziert wurden
            
            **Formel:** FN / (FN + TP)
            
            **Beispiel:**
            - 100 echte Pumps
            - 15 wurden verpasst (FN)
            - **FNR = 15%**
            
            **Praktische Bedeutung:**
            - Niedrige FNR = Wenige verpasste Chancen
            - **Ziel:** <10% ist gut, <5% ist sehr gut
            """)
            
        adv_col1, adv_col2, adv_col3, adv_col4 = st.columns(4)
        with adv_col1:
            roc_auc = model.get('roc_auc')
            if roc_auc:
                quality = "ðŸŸ¢ Sehr gut" if roc_auc > 0.9 else "ðŸŸ¡ Gut" if roc_auc > 0.7 else "ðŸ”´ Verbesserung nÃ¶tig"
                st.metric("ROC-AUC", f"{roc_auc:.4f}", help=f"Area Under ROC Curve. {quality} (>0.7 = gut)")
                st.caption(quality)
            else:
                st.write("ROC-AUC: N/A")
        
        with adv_col2:
            mcc = model.get('mcc')
            if mcc:
                quality = "ðŸŸ¢ Sehr gut" if mcc > 0.5 else "ðŸŸ¡ Gut" if mcc > 0.3 else "ðŸ”´ Verbesserung nÃ¶tig"
                st.metric("MCC", f"{mcc:.4f}", help=f"Matthews Correlation Coefficient. {quality}")
                st.caption(quality)
            else:
                st.write("MCC: N/A")
        
        with adv_col3:
            fpr = model.get('fpr')
            if fpr is not None:
                quality = "ðŸŸ¢ Gut" if fpr < 0.1 else "ðŸŸ¡ MÃ¤ÃŸig" if fpr < 0.3 else "ðŸ”´ Verbesserung nÃ¶tig"
                st.metric("False Positive Rate", f"{fpr:.4f}", help=f"Falsch-Positiv-Rate. {quality} (niedriger = besser)")
                st.caption(quality)
            else:
                st.write("FPR: N/A")
        
        with adv_col4:
            fnr = model.get('fnr')
            if fnr is not None:
                quality = "ðŸŸ¢ Gut" if fnr < 0.1 else "ðŸŸ¡ MÃ¤ÃŸig" if fnr < 0.3 else "ðŸ”´ Verbesserung nÃ¶tig"
                st.metric("False Negative Rate", f"{fnr:.4f}", help=f"Falsch-Negativ-Rate. {quality} (niedriger = besser)")
                st.caption(quality)
            else:
                st.write("FNR: N/A")

    # Cross-Validation - auÃŸerhalb des erweiterten Metriken Expanders
    cv_scores = model.get('cv_scores')
    if cv_scores:
        st.divider()
        st.subheader("ðŸ”€ Cross-Validation")

        # ErklÃ¤rung zu Cross-Validation
        st.info("**â„¹ï¸ Was ist Cross-Validation?** Cross-Validation testet die GeneralisierungsfÃ¤higkeit eines Modells durch mehrfaches Training mit verschiedenen Daten-Teilen.")
        with st.expander("ðŸ“– Detaillierte ErklÃ¤rung zu Cross-Validation", expanded=False):
                st.markdown("""
                **Cross-Validation (CV)** ist eine Methode, um die GeneralisierungsfÃ¤higkeit eines Modells zu testen.
                
                **Wie es funktioniert:**
                1. Die Trainingsdaten werden in mehrere "Folds" (z.B. 5) aufgeteilt
                2. Das Modell wird 5x trainiert:
                   - Jedes Mal wird ein anderer Fold als Test-Set verwendet
                   - Die anderen 4 Folds werden zum Training verwendet
                3. FÃ¼r jeden Fold wird die Performance gemessen
                4. Am Ende erhÃ¤lt man 5 verschiedene Scores
                
                **Vorteile:**
                - **Robustheit:** Zeigt, ob das Modell konsistent gut performt
                - **Overfitting-Erkennung:** GroÃŸe Unterschiede zwischen Train- und CV-Score deuten auf Overfitting hin
                - **Bessere SchÃ¤tzung:** Der Durchschnittswert ist eine bessere SchÃ¤tzung der echten Performance
                
                **Interpretation:**
                - **Durchschnittlicher Score:** Durchschnittliche Performance Ã¼ber alle Folds
                  - Sollte nahe am Trainings-Score sein
                
                - **Standardabweichung:** Wie stark variieren die Scores?
                  - **Niedrig (<0.05):** Modell ist stabil und konsistent
                  - **Hoch (>0.1):** Modell ist instabil, Performance variiert stark
                
                - **Overfitting-Gap:** Unterschied zwischen Train- und CV-Score
                  - **<0.1:** OK, Modell generalisiert gut
                  - **>0.1:** âš ï¸ Overfitting-Risiko - Modell lernt zu spezifisch
                
                **ðŸ’¡ Praktische Bedeutung:**
                - Ein Modell mit hohem CV-Score und niedriger Standardabweichung ist zuverlÃ¤ssiger
                - Ein groÃŸes Overfitting-Gap bedeutet: Modell funktioniert gut auf Trainingsdaten, aber schlecht auf neuen Daten
                """)

        if isinstance(cv_scores, dict):
            cv_col1, cv_col2, cv_col3 = st.columns(3)
            with cv_col1:
                mean_score = cv_scores.get('mean_score')
                if mean_score is not None:
                    quality = "ðŸŸ¢ Sehr gut" if mean_score > 0.8 else "ðŸŸ¡ Gut" if mean_score > 0.7 else "ðŸ”´ Verbesserung nÃ¶tig"
                    st.metric("Durchschnittlicher Score", f"{mean_score:.4f}", help="Durchschnittliche Performance Ã¼ber alle CV-Splits")
                    st.caption(quality)

            with cv_col2:
                std_score = cv_scores.get('std_score')
                if std_score is not None:
                    quality = "ðŸŸ¢ Stabil" if std_score < 0.05 else "ðŸŸ¡ MÃ¤ÃŸig" if std_score < 0.1 else "ðŸ”´ Instabil"
                    st.metric("Standardabweichung", f"{std_score:.4f}", help="Wie stark variiert die Performance? (niedriger = stabiler)")
                    st.caption(quality)

            with cv_col3:
                cv_overfitting = model.get('cv_overfitting_gap')
                if cv_overfitting is not None:
                    quality = "ðŸŸ¢ OK" if cv_overfitting < 0.1 else "ðŸŸ¡ âš ï¸ Overfitting-Risiko"
                    st.metric("Overfitting-Gap", f"{cv_overfitting:.4f}", help=f"Unterschied zwischen Train- und CV-Score. {quality}")
                    st.caption(quality)

            # Einzelne Scores
            individual_scores = cv_scores.get('scores', [])
            if individual_scores:
                with st.expander("ðŸ“Š Einzelne CV-Scores anzeigen"):
                    st.write(f"**Scores pro Fold:** {[f'{s:.4f}' for s in individual_scores]}")
                    st.caption(f"Anzahl Folds: {len(individual_scores)}")
    
    # TAB 3: Konfiguration
    with tab_config:
        # ErklÃ¤rung zur Konfiguration
        with st.expander("â„¹ï¸ Was bedeuten diese Konfigurations-Parameter?", expanded=False):
            st.markdown("""
            ### Training-Zeitraum
            **Was es ist:** Der Zeitraum, aus dem die Trainingsdaten stammen
            
            **Bedeutung:**
            - **LÃ¤ngerer Zeitraum** = Mehr Daten, aber mÃ¶glicherweise veraltete Muster
            - **KÃ¼rzerer Zeitraum** = Aktuellere Daten, aber weniger Beispiele
            - **Empfehlung:** 1-4 Wochen fÃ¼r aktuelle Marktbedingungen
            
            ---
            
            ### Ziel-Konfiguration
            **Was es ist:** Definiert, was das Modell vorhersagen soll
            
            **Zeitbasierte Vorhersage:**
            - **Beispiel:** "Preis wird in 5 Minuten um mindestens 3% steigen"
            - **Variable:** Welche Variable wird beobachtet (z.B. `price_close`)
            - **Zeitraum:** Wie viele Minuten in die Zukunft?
            - **Min. Ã„nderung:** Mindest-Prozent-Ã„nderung fÃ¼r "Positiv"
            - **Richtung:** Steigt (up) oder fÃ¤llt (down)?
            
            **Klassische Vorhersage:**
            - **Beispiel:** "price_close > 0.001"
            - **Variable:** Welche Variable wird geprÃ¼ft
            - **Operator:** Vergleichsoperator (>, <, >=, <=, ==)
            - **Wert:** Vergleichswert
            
            ---
            
            ### Feature-Engineering
            **Was es ist:** Automatische Erstellung zusÃ¤tzlicher Features aus Basis-Daten
            
            **Beispiele:**
            - `price_change_5` - PreisÃ¤nderung in den letzten 5 Minuten
            - `volume_ratio_10` - VerhÃ¤ltnis von Buy- zu Sell-Volumen (10 Min)
            - `ath_distance_pct` - Abstand zum All-Time High
            - `whale_activity_5` - Whale-AktivitÃ¤t in den letzten 5 Minuten
            
            **Vorteile:**
            - Modell kann komplexere Muster erkennen
            - Bessere Performance bei Pump-Erkennung
            - **Nachteil:** LÃ¤ngere Trainingszeit
            
            ---
            
            ### SMOTE (Synthetic Minority Oversampling Technique)
            **Was es ist:** Technik zur Behandlung unausgewogener Daten
            
            **Problem:** Wenn es viel mehr "Nicht-Pumps" als "Pumps" gibt, lernt das Modell hauptsÃ¤chlich "Nicht-Pump" zu sagen
            
            **LÃ¶sung:** SMOTE erstellt kÃ¼nstliche "Pump"-Beispiele, um das VerhÃ¤ltnis auszugleichen
            
            **Empfehlung:** Aktiviert lassen, wenn Daten unausgewogen sind
            
            ---
            
            ### Cross-Validation Splits
            **Was es ist:** Anzahl der Folds fÃ¼r Cross-Validation
            
            **Typische Werte:** 5 oder 10
            - **5 Folds:** Schneller, weniger robust
            - **10 Folds:** Langsamer, robuster
            
            **Empfehlung:** 5 fÃ¼r schnelle Tests, 10 fÃ¼r finale Modelle
            """)
    
        config_col1, config_col2 = st.columns(2)
        
        with config_col1:
            st.subheader("ðŸ“… Training-Zeitraum")
            train_start = model.get('train_start')
            train_end = model.get('train_end')
            if train_start and train_end:
                try:
                    if isinstance(train_start, str):
                        start_dt = datetime.fromisoformat(train_start.replace('Z', '+00:00'))
                    else:
                        start_dt = train_start
                    if isinstance(train_end, str):
                        end_dt = datetime.fromisoformat(train_end.replace('Z', '+00:00'))
                    else:
                        end_dt = train_end
                    
                    start_str = start_dt.strftime("%d.%m.%Y %H:%M")
                    end_str = end_dt.strftime("%d.%m.%Y %H:%M")
                    duration_days = (end_dt - start_dt).total_seconds() / 86400.0
                    
                    st.write(f"**Start:** {start_str}")
                    st.write(f"**Ende:** {end_str}")
                    st.write(f"**Dauer:** {duration_days:.1f} Tage")
                except Exception as e:
                    st.write(f"Start: {train_start}")
                    st.write(f"Ende: {train_end}")
            else:
                st.write("Zeitraum nicht verfÃ¼gbar")
            
            st.subheader("ðŸŽ¯ Ziel-Konfiguration")
            target_var = model.get('target_variable', 'N/A')
            target_operator = model.get('target_operator')
            target_value = model.get('target_value')
            
            # Zeitbasierte Vorhersage?
            future_minutes = model.get('future_minutes')
            price_change = model.get('price_change_percent')
            direction = model.get('target_direction')
            
            if future_minutes and price_change:
                st.write(f"**Typ:** â° Zeitbasierte Vorhersage")
                st.write(f"**Variable:** `{target_var}`")
                st.write(f"**Zeitraum:** {future_minutes} Minuten")
                st.write(f"**Min. Ã„nderung:** {price_change}%")
                direction_text = "ðŸ“ˆ Steigt" if direction == "up" else "ðŸ“‰ FÃ¤llt" if direction == "down" else "N/A"
                st.write(f"**Richtung:** {direction_text}")
            else:
                st.write(f"**Typ:** ðŸŽ¯ Klassische Bedingung")
                st.write(f"**Variable:** `{target_var}`")
                if target_operator and target_value is not None:
                    st.write(f"**Bedingung:** `{target_var} {target_operator} {target_value}`")
                else:
                    st.write("**Bedingung:** Nicht konfiguriert")
            
            st.subheader("ðŸ“Š Daten-Konfiguration")
            features_list = model.get('features', [])
            if features_list:
                st.write(f"**Features:** {len(features_list)} ausgewÃ¤hlt")
                with st.expander("ðŸ“‹ Alle Features anzeigen"):
                    for feat in features_list:
                        st.write(f"- `{feat}`")
            else:
                st.write("Keine Features verfÃ¼gbar")
            
            phases_list = model.get('phases')
            if phases_list:
                st.write(f"**Phasen:** {len(phases_list)} Phase(n)")
                with st.expander("ðŸ“‹ Phasen anzeigen"):
                    for phase_id in phases_list:
                        st.write(f"- Phase {phase_id}")
            else:
                st.write("**Phasen:** Alle Phasen verwendet")
        
        with config_col2:
            st.subheader("âš™ï¸ Modell-Parameter")
            params = model.get('params', {})
            if isinstance(params, str):
                import json
                try:
                    params = json.loads(params)
                except:
                    params = {}
            
            if params:
                # Feature-Engineering
                if params.get('use_engineered_features'):
                    st.success("ðŸ”§ Feature-Engineering: âœ… Aktiviert")
                    windows = params.get('feature_engineering_windows', [])
                    if windows:
                        st.caption(f"   Fenster: {windows}")
                else:
                    st.info("ðŸ”§ Feature-Engineering: âŒ Deaktiviert")
                
                # Zeitbasierte Vorhersage
                if params.get('_time_based', {}).get('enabled'):
                    time_based_params = params.get('_time_based', {})
                    tb_future_minutes = time_based_params.get('future_minutes') or future_minutes
                    tb_min_percent = time_based_params.get('min_percent_change') or price_change
                    tb_direction = time_based_params.get('direction') or direction
                    if tb_future_minutes and tb_min_percent:
                        direction_text = "steigt" if tb_direction == "up" else "fÃ¤llt" if tb_direction == "down" else ""
                        st.success(f"â° Zeitbasierte Vorhersage: âœ… ({tb_future_minutes}min, {tb_min_percent}% {direction_text})")
                    else:
                        st.success("â° Zeitbasierte Vorhersage: âœ… Aktiviert")
                
                # SMOTE
                if params.get('use_smote') is False:
                    st.info("âš–ï¸ SMOTE: âŒ Deaktiviert")
                else:
                    st.success("âš–ï¸ SMOTE: âœ… Aktiviert")
                
                # TimeSeriesSplit
                if params.get('use_timeseries_split') is False:
                    st.info("ðŸ”€ TimeSeriesSplit: âŒ Deaktiviert")
                else:
                    st.success("ðŸ”€ TimeSeriesSplit: âœ… Aktiviert")
                
                # CV-Splits
                cv_splits = params.get('cv_splits')
                if cv_splits:
                    st.write(f"ðŸ”€ Cross-Validation: {cv_splits} Splits")
                
                # Hyperparameter
                st.subheader("ðŸŽ›ï¸ Hyperparameter")
                hyperparams = []
                if params.get('n_estimators'):
                    hyperparams.append(f"n_estimators: {params['n_estimators']}")
                if params.get('max_depth'):
                    hyperparams.append(f"max_depth: {params['max_depth']}")
                if params.get('learning_rate'):
                    hyperparams.append(f"learning_rate: {params['learning_rate']}")
                if params.get('min_samples_split'):
                    hyperparams.append(f"min_samples_split: {params['min_samples_split']}")
                if params.get('min_samples_leaf'):
                    hyperparams.append(f"min_samples_leaf: {params['min_samples_leaf']}")
                
                if hyperparams:
                    for hp in hyperparams:
                        st.code(hp, language=None)
                else:
                    st.caption("Standard-Hyperparameter verwendet")
            else:
                st.write("Keine Parameter verfÃ¼gbar")
    
    # TAB 4: Features
    with tab_features:
        # Feature Importance Chart
        if model.get('feature_importance'):
            st.subheader("ðŸŽ¯ Feature Importance")
            
            # ErklÃ¤rung zu Feature Importance
            with st.expander("â„¹ï¸ Was ist Feature Importance?", expanded=False):
                st.markdown("""
                **Feature Importance** zeigt, welche Features am wichtigsten fÃ¼r die Vorhersagen des Modells sind.
                
                **Wie wird es berechnet?**
                - **Random Forest / XGBoost:** Misst, wie oft ein Feature zur Verbesserung der Vorhersage beitrÃ¤gt
                - **HÃ¶here Werte** = Feature ist wichtiger fÃ¼r die Vorhersage
                - **Niedrigere Werte** = Feature hat weniger Einfluss
                
                **Was bedeutet das praktisch?**
                - **Top Features** sind die wichtigsten Indikatoren fÃ¼r Pump-Erkennung
                - Features mit hoher Importance sollten bei der Datenanalyse priorisiert werden
                - Features mit sehr niedriger Importance kÃ¶nnten mÃ¶glicherweise entfernt werden
                
                **Beispiele fÃ¼r wichtige Features:**
                - `dev_sold_amount` - Wichtigster Rug-Pull-Indikator
                - `price_vs_ath_pct` - Wie nah am All-Time High?
                - `buy_pressure_ratio` - VerhÃ¤ltnis von KÃ¤ufen zu VerkÃ¤ufen
                - `volume_sol` - Handelsvolumen
                - `whale_buy_volume_sol` - GroÃŸe KÃ¤ufe (Whales)
                
                **ðŸ’¡ Interpretation:**
                - Wenn `dev_sold_amount` sehr hoch ist â†’ Modell erkennt Rug-Pulls gut
                - Wenn `price_vs_ath_pct` wichtig ist â†’ Modell nutzt ATH-Tracking effektiv
                - Wenn viele engineered Features wichtig sind â†’ Feature-Engineering war erfolgreich
                """)
            
            fi = model['feature_importance']
            if isinstance(fi, dict):
                df_fi = pd.DataFrame(list(fi.items()), columns=['Feature', 'Importance'])
                df_fi = df_fi.sort_values('Importance', ascending=False)
                
                # Top 20 Features
                st.write("**Top 20 wichtigste Features:**")
                st.dataframe(df_fi.head(20), use_container_width=True, hide_index=True)
                
                # Visualisierung
                fig = px.bar(df_fi.head(20), x='Feature', y='Importance', title="Feature Importance (Top 20)")
                fig.update_xaxes(tickangle=-45)
                fig.update_layout(height=500)
                st.plotly_chart(fig, use_container_width=True)
                
                # Interpretation der Top Features
                top_5_features = df_fi.head(5)
                st.info(f"""
                **ðŸ” Top 5 wichtigste Features:**
                {chr(10).join([f"1. **{row['Feature']}** ({row['Importance']:.4f})" for idx, row in top_5_features.iterrows()])}
                
                Diese Features tragen am meisten zur Pump-Erkennung bei.
                """)
                
                # Statistiken
                st.subheader("ðŸ“Š Feature-Statistiken")
                stat_col1, stat_col2, stat_col3 = st.columns(3)
                with stat_col1:
                    st.metric("Gesamt Features", len(df_fi))
                with stat_col2:
                    st.metric("Durchschnittliche Importance", f"{df_fi['Importance'].mean():.4f}")
                with stat_col3:
                    st.metric("Max Importance", f"{df_fi['Importance'].max():.4f}")
        else:
            st.info("â„¹ï¸ Keine Feature Importance Daten verfÃ¼gbar")
    
    # TAB 5: Details (JSON)
    with tab_details:
        st.subheader("ðŸ“‹ VollstÃ¤ndige Modell-Daten")
        st.caption("Alle verfÃ¼gbaren Daten des Modells im JSON-Format")
        st.json(model)
    
    # ZurÃ¼ck-Button (auch in Sidebar verfÃ¼gbar)
    col1, col2 = st.columns([1, 3])
    with col1:
        if st.button("â† ZurÃ¼ck zur Ãœbersicht", key="back_to_overview_bottom", use_container_width=True):
            st.session_state.pop('page', None)
            st.session_state.pop('details_model_id', None)